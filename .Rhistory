reticulate::use_python(NULL)
.rs.restartR()
install.packages("yaml")
library(yaml)  # For parsing YAML
library(fs)    # For file system operations
# Define the directory where your Quarto blog posts are stored
blog_directory <- "/posts"  # Update with your actual path
# Function to extract tags and categories from YAML front matter
extract_metadata <- function(file_path) {
content <- readLines(file_path)  # Read the file content
yaml_header <- yaml::read_yaml(text = paste(content[1:grep("^---$", content)[2]], collapse = "\n"))  # Extract YAML
# Extract tags and categories
tags <- yaml_header$tags
categories <- yaml_header$categories
return(list(tags = tags, categories = categories))
}
# Get all .qmd files in the blog directory
files <- dir_ls(blog_directory, glob = "*.qmd")
# Extract metadata from all files
metadata <- lapply(files, extract_metadata)
# Get all .qmd files in the blog directory
files <- dir_ls(blog_directory, glob = "*.qmd")
# Define the directory where your Quarto blog posts are stored
blog_directory <- "posts"  # Update with your actual path
# Function to extract tags and categories from YAML front matter
extract_metadata <- function(file_path) {
content <- readLines(file_path)  # Read the file content
yaml_header <- yaml::read_yaml(text = paste(content[1:grep("^---$", content)[2]], collapse = "\n"))  # Extract YAML
# Extract tags and categories
tags <- yaml_header$tags
categories <- yaml_header$categories
return(list(tags = tags, categories = categories))
}
# Get all .qmd files in the blog directory
files <- dir_ls(blog_directory, glob = "*.qmd")
# Extract metadata from all files
metadata <- lapply(files, extract_metadata)
# Extract unique tags and categories
tags <- unique(unlist(lapply(metadata, `[[`, "tags")))
categories <- unique(unlist(lapply(metadata, `[[`, "categories")))
# Display results
cat("Unique Tags:\n")
print(tags)
cat("\nUnique Categories:\n")
print(categories)
library(yaml)  # For parsing YAML
library(fs)    # For file system operations
# Define the directory where your Quarto blog posts are stored
blog_directory <- "posts"  # Update with your actual path
# Function to extract tags and categories from YAML front matter
extract_metadata <- function(file_path) {
content <- readLines(file_path)  # Read the file content
yaml_header <- yaml::read_yaml(text = paste(content[1:grep("^---$", content)[2]], collapse = "\n"))  # Extract YAML
# Extract tags and categories
tags <- yaml_header$tags
categories <- yaml_header$categories
return(list(tags = tags, categories = categories))
}
# Get all .qmd files recursively in the blog directory
files <- dir_ls(blog_directory, glob = "*.qmd", recursive = TRUE)
# Extract metadata from all files
metadata <- lapply(files, extract_metadata)
# Extract unique tags and categories
tags <- unique(unlist(lapply(metadata, `[[`, "tags")))
categories <- unique(unlist(lapply(metadata, `[[`, "categories")))
# Display results
cat("Unique Tags:\n")
print(tags)
cat("\nUnique Categories:\n")
print(categories)
library(yaml)  # For parsing YAML
library(fs)    # For file system operations
# Define the directory where your Quarto blog posts are stored
blog_directory <- "posts"  # Update with your actual path
# Function to extract tags and categories from YAML front matter
extract_metadata <- function(file_path) {
content <- readLines(file_path)  # Read the file content
yaml_header <- yaml::read_yaml(text = paste(content[1:grep("^---$", content)[2]], collapse = "\n"))  # Extract YAML
# Extract tags and categories
tags <- yaml_header$tags
categories <- yaml_header$categories
return(list(tags = tags, categories = categories))
}
# Get all .qmd files recursively in the blog directory
files <- dir_ls(blog_directory, glob = "*.qmd", recurse = TRUE)
# Extract metadata from all files
metadata <- lapply(files, extract_metadata)
# Extract unique tags and categories
tags <- unique(unlist(lapply(metadata, `[[`, "tags")))
categories <- unique(unlist(lapply(metadata, `[[`, "categories")))
# Display results
cat("Unique Tags:\n")
print(tags)
cat("\nUnique Categories:\n")
print(categories)
library(yaml)  # For parsing YAML
library(fs)    # For file system operations
# Define the directory where your Quarto blog posts are stored
blog_directory <- "posts"  # Update with your actual path
# Function to extract tags and categories from YAML front matter
extract_metadata <- function(file_path) {
content <- readLines(file_path)  # Read the file content
yaml_header <- yaml::read_yaml(text = paste(content[1:grep("^---$", content)[2]], collapse = "\n"))  # Extract YAML
# Extract tags and categories
tags <- yaml_header$tags
categories <- yaml_header$categories
return(list(tags = tags, categories = categories))
}
# Get all .qmd files recursively in the blog directory
files <- dir_ls(blog_directory, glob = "*.qmd", recurse = TRUE)
# Extract metadata from all files
metadata <- lapply(files, extract_metadata)
# Extract unique tags and categories
tags <- unique(unlist(lapply(metadata, `[[`, "tags")))
categories <- unique(unlist(lapply(metadata, `[[`, "categories")))
# Display results
cat("Unique Tags:\n")
print(tags)
cat("\nUnique Categories:\n")
print(categories)
quarto preview
pwd
library(rvest)
install.packages("rvest")
install.packages("httr")
install.packages("tidyverse")
library(rvest)
library(httr)
library(tidyverse)
# Define playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Fetch page content
page <- read_html(playlist_url)
# Extract video links
video_links <- page %>%
html_nodes("a.ytd-playlist-video-renderer") %>%
html_attr("href")
# Clean up and extract video IDs
video_ids <- unique(gsub("/watch\\?v=", "", video_links))
# Generate Markdown embed codes
markdown_output <- paste0("{{< video https://www.youtube.com/embed/", video_ids, " >}}")
# Save to a Markdown file
writeLines(markdown_output, "cradletograver_playlist.md")
# Print to console
print(markdown_output)
library(rvest)
library(httr)
library(tidyverse)
# Define playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Fetch page content
page <- read_html(playlist_url)
# Extract video links
video_links <- page %>%
html_nodes("a.ytd-playlist-video-renderer") %>%
html_attr("href")
# Clean up and extract video IDs
video_ids <- unique(gsub("/watch\\?v=", "", video_links))
# Generate Markdown embed codes
markdown_output <- paste0("{{< video https://www.youtube.com/embed/", video_ids, " >}}")
# Save to a Markdown file
writeLines(markdown_output, "cradletograver_playlist.md")
# Print to console
print(markdown_output)
# Load required libraries
install.packages("tidyverse", repos='http://cran.rstudio.com/')
install.packages("rvest", repos='http://cran.rstudio.com/')
install.packages("httr", repos='http://cran.rstudio.com/')
library(rvest)
library(httr)
library(tidyverse)
# Define the YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Fetch HTML content of the playlist page
page <- read_html(playlist_url)
# Extract video links
video_links <- page %>%
html_nodes("a.ytd-playlist-video-renderer") %>%
html_attr("href")
# Extract only the video IDs
video_ids <- unique(gsub("/watch\\?v=", "", video_links))
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
# Load required libraries
install.packages("tidyverse", repos='http://cran.rstudio.com/')
install.packages("rvest", repos='http://cran.rstudio.com/')
install.packages("httr", repos='http://cran.rstudio.com/')
library(rvest)
library(httr)
library(tidyverse)
# Define the YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Fetch HTML content of the playlist page
page <- read_html(playlist_url)
# Extract video links
video_links <- page %>%
html_nodes("a.ytd-playlist-video-renderer") %>%
html_attr("href")
# Extract only the video IDs
video_ids <- unique(gsub("/watch\\?v=", "", video_links))
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Define the file to store video IDs
video_ids_file <- "video_ids.txt"
# Run yt-dlp in R to get video IDs
system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}' > {video_ids_file}"))
# Read extracted video IDs
if (file.exists(video_ids_file)) {
video_ids <- readLines(video_ids_file)
} else {
stop("Error: No video IDs found. Check if yt-dlp is installed and working.")
}
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Define the file to store video IDs
video_ids_file <- "video_ids.txt"
# Run yt-dlp in R to get video IDs
system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}' > {video_ids_file}"))
# Read extracted video IDs
if (file.exists(video_ids_file)) {
video_ids <- readLines(video_ids_file)
} else {
stop("Error: No video IDs found. Check if yt-dlp is installed and working.")
}
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Define the file to store video IDs
video_ids_file <- "video_ids.txt"
# Run yt-dlp in R to get video IDs
system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}' > {video_ids_file}"))
# Read extracted video IDs
if (file.exists(video_ids_file)) {
video_ids <- readLines(video_ids_file)
} else {
stop("Error: No video IDs found. Check if yt-dlp is installed and working.")
}
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Define the file to store video IDs
video_ids_file <- "video_ids.txt"
# Run yt-dlp in R to get video IDs
system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}' > {video_ids_file}"))
# Read extracted video IDs
if (file.exists(video_ids_file)) {
video_ids <- readLines(video_ids_file)
} else {
stop("Error: No video IDs found. Check if yt-dlp is installed and working.")
}
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp in R to get video IDs and capture the output directly
video_ids <- system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}'"), intern = TRUE)
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp in R to get video IDs and capture the output directly
video_ids <- system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}'"), intern = TRUE)
library(glue)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp in R to get video IDs and capture the output directly
video_ids <- system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}'"), intern = TRUE)
library(tidyverse)
library(glue)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp in R to get video IDs and capture the output directly
video_ids <- system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}'"), intern = TRUE)
library(tidyverse)
library(glue)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp in R to get video IDs and capture the output directly
video_ids <- system(glue::glue("yt-dlp --flat-playlist --get-id '{playlist_url}'"), intern = TRUE)
# Ensure video IDs were found
if (length(video_ids) == 0) {
stop("Error: No video IDs found. Double-check the playlist URL.")
}
# Generate Markdown embed codes for Quarto
markdown_output <- paste0("{{< video https://www.youtube.com/embed/", video_ids, " >}}")
# Save to a Markdown file
output_file <- "cradletograver_playlist.md"
writeLines(markdown_output, output_file)
# Print success message
cat("Markdown file generated successfully! Check:", output_file, "\n")
# Print output to console
print(markdown_output)
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp in R to get video IDs and titles
# Use --get-id and --get-title to extract both
playlist_info <- system(glue::glue("yt-dlp --flat-playlist --get-id --get-title '{playlist_url}'"), intern = TRUE)
# Ensure data was found
if (length(playlist_info) == 0) {
stop("Error: No video data found. Double-check the playlist URL.")
}
# Split the output into IDs and titles
video_ids <- playlist_info[seq(1, length(playlist_info), 2)]  # Odd indices are IDs
video_titles <- playlist_info[seq(2, length(playlist_info), 2)]  # Even indices are titles
# Ensure video IDs and titles are aligned
if (length(video_ids) != length(video_titles)) {
stop("Error: Mismatch between video IDs and titles.")
}
# Generate Markdown embed codes with titles
markdown_output <- paste0(
"## ", video_titles, "\n\n",  # Add a header for each video title
"{{< video https://www.youtube.com/embed/", video_ids, " >}}\n\n",  # Video embed
"---\n"  # Add a horizontal rule for separation
)
# Print markdown_output to confirm it contains data
cat(markdown_output, sep = "\n")
# Save to a Markdown file
output_file <- "cradletograver_playlist.md"
writeLines(markdown_output, output_file)
# Confirm the file was written
if (file.exists(output_file)) {
cat("File written successfully:", output_file, "\n")
cat("File contents:\n")
cat(readLines(output_file), sep = "\n")
} else {
stop("Error: File was not written. Check permissions or working directory.")
}
library(tidyverse)
# Define YouTube Playlist URL
playlist_url <- "https://www.youtube.com/playlist?list=PLuak_bGvcWZO0Da0cDVBpDeTQPEWpuvCD"
# Run yt-dlp to get video IDs and titles
# Use --get-id and --get-title together
playlist_info <- system(glue::glue("yt-dlp --flat-playlist --get-id --get-title '{playlist_url}'"), intern = TRUE)
# Ensure data was found
if (length(playlist_info) == 0) {
stop("Error: No video data found. Double-check the playlist URL.")
}
# Split the output into IDs and titles
# yt-dlp outputs IDs and titles in alternating lines
video_ids <- playlist_info[seq(1, length(playlist_info), 2)]  # Odd lines are IDs
video_titles <- playlist_info[seq(2, length(playlist_info), 2)]  # Even lines are titles
# Ensure video IDs and titles are aligned
if (length(video_ids) != length(video_titles)) {
stop("Error: Mismatch between video IDs and titles.")
}
# Generate Markdown embed codes with titles
markdown_output <- paste0(
"## ", video_titles, "\n\n",  # Add a header for each video title
"{{< video https://www.youtube.com/embed/", video_ids, " >}}\n\n",  # Video embed
"---\n"  # Add a horizontal rule for separation
)
# Print markdown_output to confirm it contains data
cat(markdown_output, sep = "\n")
# Save to a Markdown file
output_file <- "cradletograver_playlist.md"
writeLines(markdown_output, output_file)
# Confirm the file was written
if (file.exists(output_file)) {
cat("File written successfully:", output_file, "\n")
cat("File contents:\n")
cat(readLines(output_file), sep = "\n")
} else {
stop("Error: File was not written. Check permissions or working directory.")
}
pwd
ls
ls
pwd
quarto preview
